<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Michael Boyle — AI Journey</title><link href="/" rel="alternate"></link><link href="/feeds/all-en.atom.xml" rel="self"></link><id>/</id><updated>2025-10-16T00:00:00+01:00</updated><entry><title>Week 1 — Local LLMs: Ollama vs OpenAI SDK</title><link href="/blog/2025/10/week-1-local-llms-ollama-vs-openai-sdk/" rel="alternate"></link><published>2025-10-16T00:00:00+01:00</published><updated>2025-10-16T00:00:00+01:00</updated><author><name>Michael Boyle</name></author><id>tag:None,2025-10-16:/blog/2025/10/week-1-local-llms-ollama-vs-openai-sdk/</id><summary type="html">&lt;p&gt;Comparing local vs hosted models with the same client code.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Goal: talk to a local model (Ollama) &lt;em&gt;and&lt;/em&gt; a hosted model using one OpenAI-style client.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What worked&lt;/strong&gt;
- Keep prompts tiny and specific
- Match temperature/top_p for fairness
- Log token counts, not vibes&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Snippet&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;openai&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;OpenAI&lt;/span&gt;
&lt;span class="n"&gt;client&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;OpenAI&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;base_url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;http://localhost:11434/v1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;api_key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;ollama&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;resp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;client&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;chat&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;completions&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;llama3.2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;messages&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;role&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;user&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;content&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;3 bullets on what I learned today&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}],&lt;/span&gt;
    &lt;span class="n"&gt;temperature&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;resp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choices&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;message&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content><category term="misc"></category><category term="LLMs"></category><category term="SDK"></category><category term="Python"></category></entry><entry><title>Shipping GridWord v2 — UI lessons from Gradio</title><link href="/blog/2025/10/shipping-gridword-v2-ui-lessons-from-gradio/" rel="alternate"></link><published>2025-10-14T00:00:00+01:00</published><updated>2025-10-14T00:00:00+01:00</updated><author><name>Michael Boyle</name></author><id>tag:None,2025-10-14:/blog/2025/10/shipping-gridword-v2-ui-lessons-from-gradio/</id><summary type="html">&lt;p&gt;Calmer visuals, fewer layout shifts, better readability.&lt;/p&gt;</summary><content type="html">&lt;ul&gt;
&lt;li&gt;Reduced color noise, increased spacing&lt;/li&gt;
&lt;li&gt;Kept critical info above the fold on a 13" screen&lt;/li&gt;
&lt;li&gt;Fixed card heights to avoid layout jumps&lt;/li&gt;
&lt;/ul&gt;</content><category term="misc"></category><category term="UX"></category><category term="Gradio"></category><category term="Product"></category></entry><entry><title>How LLMs may reshape valuation work</title><link href="/blog/2025/10/how-llms-may-reshape-valuation-work/" rel="alternate"></link><published>2025-10-10T00:00:00+01:00</published><updated>2025-10-10T00:00:00+01:00</updated><author><name>Michael Boyle</name></author><id>tag:None,2025-10-10:/blog/2025/10/how-llms-may-reshape-valuation-work/</id><summary type="html">&lt;p&gt;A first-principles view of where LLMs help and where human judgement stays central.&lt;/p&gt;</summary><content type="html">&lt;ul&gt;
&lt;li&gt;Intake → structured requests + doc parsing&lt;/li&gt;
&lt;li&gt;Comparable selection → rules + human override&lt;/li&gt;
&lt;li&gt;Narrative drafting → human outline, model polish&lt;/li&gt;
&lt;li&gt;Review → checklists + diffs&lt;/li&gt;
&lt;/ul&gt;</content><category term="misc"></category><category term="Valuation"></category><category term="Strategy"></category></entry></feed>